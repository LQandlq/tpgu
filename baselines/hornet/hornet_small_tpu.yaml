runtime:
  distribution_strategy: tpu
  mixed_precision_dtype: bfloat16
task:
  model:
    num_classes: 1000
    dims: [ 96, 192, 384, 768 ]
    orders: [ 2, 3, 4, 5 ]
    drop_path_rate: 0.4
    depths: [ 2, 3, 18, 2 ]
    kernel_initializer: 'truncated_normal'
    input_size: [ 224, 224, 3 ]
  losses:
    l2_weight_decay: 0.0
    label_smoothing: 0.1
    one_hot: false
    soft_labels: True
  train_data:
    input_path: path_to_imagenet/train*
    is_training: true
    dtype: bfloat16
    global_batch_size: 128
    aug_rand_hflip: true
    aug_type:
      randaug:
        magnitude: 9
        magnitude_std: 0.5
        num_layers: 2
        exclude_ops: [Cutout]
        translate_const: 10
        prob_to_apply: 0.5
      type: randaug
    tf_resize_method: 'bicubic'
    random_erasing:
      probability: 0.25
    mixup_and_cutmix:
        mixup_alpha: 0.8
        cutmix_alpha: 1.0
        label_smoothing: 0.1
        prob: 1.0
        switch_prob: 0.5
  validation_data:
    input_path: path_to_imagenet/val*
    is_training: false
    global_batch_size: 128
    dtype: bfloat16
    drop_remainder: false
    tf_resize_method: 'bicubic'
trainer:
  best_checkpoint_export_subdir: 'best_ckpt'
  best_checkpoint_eval_metric: 'accuracy'
  best_checkpoint_metric_comp: 'higher'
  best_ema_checkpoint_export_subdir: 'ema_best_ckpt'
  best_ema_checkpoint_eval_metric: 'ema_accuracy'
  best_ema_checkpoint_metric_comp: 'higher'
  train_steps: 93600 # one training step has accumulation_steps mirco-batches
  accumulation_steps: 32
  steps_per_loop: 312
  validation_steps: 391
  validation_interval: 312
  summary_interval: 312
  checkpoint_interval: 312
  max_to_keep: 2
  preemption_on_demand_checkpoint: false
  optimizer_config:
    ema:
      average_decay: 0.9999
    learning_rate:
      cosine:
        alpha: 0.0
        decay_steps: 93600
        initial_learning_rate: 0.004
      type: cosine
    optimizer:
      adamw:
        include_in_weight_decay: [.*(kernel):0$]
        exclude_from_weight_decay: [.*(bias|beta|gamma):0$]
        weight_decay_rate: 0.05
        gradient_clip_norm: 5
      type: adamw
    warmup:
      linear:
        warmup_learning_rate: 0
        warmup_steps: 6240
      type: linear
