runtime:
  distribution_strategy: tpu
  mixed_precision_dtype: bfloat16
task:
  model:
    num_classes: 1000
    dims: [ 96, 192, 384, 768 ]
    drop_path_rate: 0.1
    depths: [ 3, 3, 9, 3 ]
    kernel_initializer: 'truncated_normal'
    input_size: [ 224, 224, 3 ]
  losses:
    l2_weight_decay: 0.0
    label_smoothing: 0.1
    one_hot: false
    soft_labels: True
  train_data:
    input_path: path_to_imagenet/train*
    is_training: true
    dtype: bfloat16
    global_batch_size: 512
    aug_rand_hflip: true
    aug_type:
      randaug:
        magnitude: 9
        magnitude_std: 0.5
        num_layers: 2
        exclude_ops: [ Cutout ]
        translate_const: 10
        prob_to_apply: 0.5
      type: randaug
    tf_resize_method: 'bicubic'
    random_erasing:
      probability: 0.25
    mixup_and_cutmix:
      mixup_alpha: 0.8
      cutmix_alpha: 1.0
      label_smoothing: 0.1
      prob: 1.0
      switch_prob: 0.5
  validation_data:
    input_path: path_to_imagenet/val*
    is_training: false
    global_batch_size: 512
    dtype: bfloat16
    drop_remainder: false
    tf_resize_method: 'bicubic'
trainer:
  best_checkpoint_export_subdir: 'best_ckpt'
  best_checkpoint_eval_metric: 'accuracy'
  best_checkpoint_metric_comp: 'higher'
  best_ema_checkpoint_export_subdir: 'ema_best_ckpt'
  best_ema_checkpoint_eval_metric: 'ema_accuracy'
  best_ema_checkpoint_metric_comp: 'higher'
  train_steps: 93600 # one step has accumulation_steps mirco-batches
  accumulation_steps: 8
  steps_per_loop: 312
  validation_steps: 98
  validation_interval: 312
  summary_interval: 312
  checkpoint_interval: 312
  max_to_keep: 2
  preemption_on_demand_checkpoint: false
  optimizer_config:
    ema:
      average_decay: 0.9999
    learning_rate:
      cosine:
        alpha: 0.0
        decay_steps: 93600
        initial_learning_rate: 0.004
      type: cosine
    optimizer:
      adamw:
        include_in_weight_decay: null
        exclude_from_weight_decay: [ .*(bias|beta|gamma):0$ ]
        weight_decay_rate: 0.05
      type: adamw
    warmup:
      linear:
        warmup_learning_rate: 0
        warmup_steps: 6240
      type: linear
